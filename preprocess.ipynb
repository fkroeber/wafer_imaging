{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "from empatches import EMPatches\n",
    "from itertools import combinations\n",
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We select the `PATCH_SIZE` to be 512 pxls such that it contains sufficient context information to be able to discriminate between flawed and flawless structures. Since we have a class imbalance with positive (flaweless) patches being abundant, we set the overlap factor during patching here to 0. Applying an overlap factor of 0.5 for the negative (flawed) patches aims at increasing the amount of negative (flawed) patches (-> augmentation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define patching parameters\n",
    "PATCH_SIZE = 512\n",
    "PATCH_OVLP_POS = 0\n",
    "PATCH_OVLP_NEG = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define input data\n",
    "data_dir = \"data/FlawDetectionTrainingImages\"\n",
    "positive_imgs = glob.glob(os.path.join(data_dir, \"positive\", \"*jpg\"))\n",
    "negative_imgs = glob.glob(os.path.join(data_dir, \"negative\", \"*jpg\"))\n",
    "\n",
    "# define output directories\n",
    "output_dir = \"data/FlawDetectionTrainingImages/patches\"\n",
    "positive_output_dir = os.path.join(output_dir, \"positive\")\n",
    "negative_output_dir = os.path.join(output_dir, \"negative\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 101/101 [00:07<00:00, 12.89it/s]\n"
     ]
    }
   ],
   "source": [
    "# a) split positive images into patches using no overlap\n",
    "\n",
    "# remove existing patches\n",
    "shutil.rmtree(positive_output_dir, ignore_errors=True)\n",
    "os.makedirs(positive_output_dir, exist_ok=True)\n",
    "\n",
    "# patch new ones\n",
    "n_patch = 0\n",
    "for img_path in tqdm(positive_imgs):\n",
    "    img = cv2.imread(img_path)\n",
    "    img_marked = cv2.imread(img_path.replace(\"negative\", \"negative_marked\"))\n",
    "    img_stem = os.path.split(img_path)[-1].split(\".jpg\")[0]\n",
    "    emp = EMPatches()\n",
    "    img_patches, indices = emp.extract_patches(img, patchsize=PATCH_SIZE, overlap=PATCH_OVLP_POS)\n",
    "    # patch\n",
    "    for i, patch in enumerate(img_patches):\n",
    "        out_path = f\"{img_stem}_{n_patch}.jpg\"\n",
    "        cv2.imwrite(os.path.join(positive_output_dir, out_path), patch)\n",
    "        n_patch += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36/36 [00:52<00:00,  1.47s/it]\n"
     ]
    }
   ],
   "source": [
    "# b) split negative images into patches using larger overlap\n",
    "\n",
    "# remove existing patches\n",
    "shutil.rmtree(negative_output_dir, ignore_errors=True)\n",
    "os.makedirs(negative_output_dir, exist_ok=True)\n",
    "shutil.rmtree(os.path.join(negative_output_dir, \"overviews\"), ignore_errors=True)\n",
    "os.makedirs(os.path.join(negative_output_dir, \"overviews\"), exist_ok=True)\n",
    "\n",
    "# patch new ones\n",
    "n_patch = 0\n",
    "for img_path in tqdm(negative_imgs):\n",
    "    img = cv2.imread(img_path)\n",
    "    img_marked = cv2.imread(img_path.replace(\"negative\", \"negative_marked\"))\n",
    "    img_stem = os.path.split(img_path)[-1].split(\".jpg\")[0]\n",
    "    emp = EMPatches()\n",
    "    img_patches, indices = emp.extract_patches(img, patchsize=PATCH_SIZE, overlap=PATCH_OVLP_NEG)\n",
    "    # patch\n",
    "    for i, patch in enumerate(img_patches):\n",
    "        out_path = f\"{img_stem}_{n_patch}.jpg\"\n",
    "        cv2.imwrite(os.path.join(negative_output_dir, out_path), patch)\n",
    "        n_patch += 1\n",
    "    # plot overview\n",
    "    fig, axs = plt.subplots(1, 1, figsize=(10, 10))\n",
    "    axs.imshow(np.flip(img_marked, 2))\n",
    "    for i, idxs in enumerate(indices):\n",
    "        rect = patches.Rectangle(\n",
    "            (idxs[2], idxs[0]),\n",
    "            PATCH_SIZE,\n",
    "            PATCH_SIZE,\n",
    "            linewidth=1,\n",
    "            edgecolor='lightblue',\n",
    "            facecolor='none'\n",
    "        )\n",
    "        axs.add_patch(rect)\n",
    "        # add label\n",
    "        axs.text(\n",
    "            idxs[2] + PATCH_SIZE//2,\n",
    "            idxs[0] + PATCH_SIZE//2,\n",
    "            str(i),\n",
    "            color='blue',\n",
    "            horizontalalignment='center',\n",
    "            verticalalignment='center',\n",
    "            fontsize=6,\n",
    "        )\n",
    "    axs.set_axis_off()\n",
    "    fig.savefig(\n",
    "        os.path.join(os.path.join(negative_output_dir, \"overviews\"), f\"{img_stem}.jpg\"),\n",
    "        bbox_inches='tight',\n",
    "        dpi=600,\n",
    "    )\n",
    "    plt.close(fig)\n",
    "    n_patch = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After this patching step, we manually inspect the resulting negative patches to split them into flawed and flawless ones. To this end, the created overviews can be used to quickly find the indices of patches being flawed. We create a new directory, where we copy-paste all created patches and move the ones that are flawless from the negative to the corresponding positive subfolder. The resulting directory called `.../patches_v1` is the input to create some splits for cross-validation as specified below.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0:\n",
      "  Train size: 4032, Flaws: 116\n",
      "  Val size: 1038, Flaws: 28\n",
      "  Test size: 1128, Flaws: 41\n",
      "Fold 1:\n",
      "  Train size: 4032, Flaws: 118\n",
      "  Val size: 920, Flaws: 29\n",
      "  Test size: 1246, Flaws: 38\n",
      "Fold 2:\n",
      "  Train size: 4032, Flaws: 130\n",
      "  Val size: 1008, Flaws: 24\n",
      "  Test size: 1158, Flaws: 31\n",
      "Fold 3:\n",
      "  Train size: 3798, Flaws: 103\n",
      "  Val size: 1096, Flaws: 46\n",
      "  Test size: 1304, Flaws: 36\n",
      "Fold 4:\n",
      "  Train size: 3798, Flaws: 113\n",
      "  Val size: 1038, Flaws: 33\n",
      "  Test size: 1362, Flaws: 39\n"
     ]
    }
   ],
   "source": [
    "# create some splits in stratified manner for cross-validation\n",
    "# stratification: a given image should be only in one fold\n",
    "\n",
    "# define input data\n",
    "patch_dir = \"data/FlawDetectionTrainingImages/patches_v1\"\n",
    "patches = [\n",
    "    *glob.glob(os.path.join(patch_dir, \"positive\", \"*jpg\")),\n",
    "    *glob.glob(os.path.join(patch_dir, \"negative\", \"*jpg\"))\n",
    "]\n",
    "\n",
    "# create dataframe\n",
    "df = pd.DataFrame(patches, columns=[\"path\"])\n",
    "df[\"label\"] = df[\"path\"].apply(lambda x: 0 if \"positive\" in x else 1)\n",
    "df[\"group\"] = df[\"path\"].apply(lambda x: os.path.split(x)[-1].rsplit(\"_\",1)[0])\n",
    "\n",
    "# StratifiedGroupKFold - stratified split according to label, grouped by image\n",
    "n_splits = 5\n",
    "seed = 12\n",
    "sgkf_l1 = StratifiedGroupKFold(n_splits=n_splits, shuffle=True, random_state=seed)\n",
    "\n",
    "for fold, (train_idx, test_idx) in enumerate(sgkf_l1.split(df, df[\"label\"], df[\"group\"])):\n",
    "    \n",
    "    # retrieve pandas data frame\n",
    "    _train_df = df.iloc[train_idx]\n",
    "    test_df = df.iloc[test_idx]\n",
    "    # split preliminary train further into train and val\n",
    "    _train_df = _train_df.reset_index(drop=True)\n",
    "    sgkf_l2 = StratifiedGroupKFold(n_splits=n_splits, shuffle=True, random_state=seed)\n",
    "    for _, (train_idx, val_idx) in enumerate(sgkf_l2.split(_train_df, _train_df[\"label\"], _train_df[\"group\"])):\n",
    "        # retrieve pandas data frame\n",
    "        train_df = _train_df.iloc[train_idx]\n",
    "        val_df = _train_df.iloc[val_idx]\n",
    "    # sanity check - train and val/test set should not overlap\n",
    "    assert len(set(train_df.group.unique()).intersection(set(val_df.group.unique()))) == 0\n",
    "    assert len(set(train_df.group.unique()).intersection(set(test_df.group.unique()))) == 0\n",
    "\n",
    "    # print stats\n",
    "    print(f\"Fold {fold}:\")\n",
    "    print(f\"  Train size: {len(train_df)}, Flaws: {int(train_df.value_counts('label')[1])}\")\n",
    "    print(f\"  Val size: {len(val_df)}, Flaws: {int(val_df.value_counts('label')[1])}\")\n",
    "    print(f\"  Test size: {len(test_df)}, Flaws: {int(test_df.value_counts('label')[1])}\")\n",
    "\n",
    "    # merge train val and test set to single df with train/val/test labels\n",
    "    train_df = train_df.copy()\n",
    "    val_df = val_df.copy()\n",
    "    test_df = test_df.copy()\n",
    "    train_df.loc[:, \"split\"] = \"train\"\n",
    "    val_df.loc[:, \"split\"] = \"val\"\n",
    "    test_df.loc[:, \"split\"] = \"test\"\n",
    "    split_df = pd.concat([train_df, val_df, test_df], ignore_index=True)\n",
    "    split_df.to_csv(os.path.join(patch_dir, f\"split_{fold}.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0:\n",
      "  train: total size: 368, flaws: 116, guess accuracy: 0.68\n",
      "  val: total size: 88, flaws: 28, guess accuracy: 0.68\n",
      "  test: total size: 99, flaws: 41, guess accuracy: 0.59\n",
      "Fold 1:\n",
      "  train: total size: 370, flaws: 118, guess accuracy: 0.68\n",
      "  val: total size: 76, flaws: 29, guess accuracy: 0.62\n",
      "  test: total size: 109, flaws: 38, guess accuracy: 0.65\n",
      "Fold 2:\n",
      "  train: total size: 382, flaws: 130, guess accuracy: 0.66\n",
      "  val: total size: 80, flaws: 24, guess accuracy: 0.70\n",
      "  test: total size: 93, flaws: 31, guess accuracy: 0.67\n",
      "Fold 3:\n",
      "  train: total size: 342, flaws: 103, guess accuracy: 0.70\n",
      "  val: total size: 105, flaws: 46, guess accuracy: 0.56\n",
      "  test: total size: 108, flaws: 36, guess accuracy: 0.67\n",
      "Fold 4:\n",
      "  train: total size: 349, flaws: 113, guess accuracy: 0.68\n",
      "  val: total size: 92, flaws: 33, guess accuracy: 0.64\n",
      "  test: total size: 114, flaws: 39, guess accuracy: 0.66\n"
     ]
    }
   ],
   "source": [
    "# create almost balanced cross-validation splits\n",
    "# to see if network can be trained properly under these simplified conditions\n",
    "\n",
    "for fold in range(n_splits):\n",
    "\n",
    "    # subsample & balance patches (ratio 2:1)\n",
    "    df = pd.read_csv(os.path.join(patch_dir, f\"split_{fold}.csv\"))\n",
    "    pos_sample_ratio = 2 * df.value_counts(\"label\")[1]\n",
    "    df = pd.concat([\n",
    "        df[df[\"label\"] == 0].sample(pos_sample_ratio, random_state=42),\n",
    "        df[df[\"label\"] == 1]\n",
    "    ])\n",
    "    df = df.reset_index(drop=True)\n",
    "\n",
    "    # sanity check: ensure image groups are non-overlapping between splits\n",
    "    imgs_per_split = df.groupby(\"split\").apply(lambda x: x.group.unique(), include_groups=False)\n",
    "    split_combis = combinations([\"train\", \"val\", \"test\"], 2)\n",
    "    for split_combi in split_combis:\n",
    "        intersect = set(imgs_per_split[split_combi[0]]) & set(imgs_per_split[split_combi[1]])\n",
    "        assert len(intersect) == 0\n",
    "\n",
    "    # write to disk patches\n",
    "    df.to_csv(\n",
    "        os.path.join(patch_dir, f\"split_balanced_{fold}.csv\"),\n",
    "        index=False\n",
    "    )\n",
    "\n",
    "    # print stats\n",
    "    print(f\"Fold {fold}:\")\n",
    "    for split in [\"train\", \"val\", \"test\"]:\n",
    "        size = len(df[df['split'] == split])\n",
    "        pos = df[df['split'] == split].value_counts('label')[1]\n",
    "        print(f\"  {split}: total size: {size}, flaws: {pos}, guess accuracy: {max(pos/size, 1-(pos/size)):.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wafer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
